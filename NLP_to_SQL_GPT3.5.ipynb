{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "##                                                    CCC - NLP to SQL generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import os\n",
    "import langchain.llms as llms\n",
    "from langchain.chains import create_sql_query_chain\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain.prompts import PromptTemplate\n",
    "import openpyxl\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain_community.agent_toolkits import create_sql_agent\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current working directory: C:\\Users\\nithi\\OneDrive - University of Illinois Chicago\\Documents\\Capstone project\\LLM project\n"
     ]
    }
   ],
   "source": [
    "working_dir = \"C:/Users/nithi/OneDrive - University of Illinois Chicago/Documents/Capstone project/LLM project\"\n",
    "os.chdir(working_dir)\n",
    "\n",
    "print(f\"The current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing and loading the csv file to SQLite Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from 'dataset_flattened.csv' has been successfully saved to 'dataset.db' in the table 'models'.\n"
     ]
    }
   ],
   "source": [
    "# Load CSV file\n",
    "csv_file = 'dataset_flattened.csv'\n",
    "df = pd.read_csv(csv_file)  \n",
    "\n",
    "# Save to SQLite DB\n",
    "db_file = 'dataset.db'  \n",
    "conn = sqlite3.connect(db_file)\n",
    "table_name = 'models'\n",
    "df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "conn.close()\n",
    "\n",
    "print(f\"Data from '{csv_file}' has been successfully saved to '{db_file}' in the table '{table_name}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Names: ['models']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[(4797,)]'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SQLite database connection\n",
    "db = SQLDatabase.from_uri(\"sqlite:///dataset.db\")\n",
    "\n",
    "# List all the available table names in the database\n",
    "print(\"Table Names:\", db.get_usable_table_names())\n",
    "\n",
    "# Execute the query\n",
    "db.run(\"SELECT count(*) from models\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Developing a chain with sample example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT DISTINCT \"Company_Name\" \\nFROM models\\nORDER BY \"Company_Name\"\\nLIMIT 5;'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPT connection\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "\n",
    "#First Chain to take the user input and convert it to a SQL query\n",
    "write_query = create_sql_query_chain(llm, db)\n",
    "response = write_query.invoke({\"question\": \"What is the \"})\n",
    "response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[('Allstate',), ('Liberty Mutual',), ('Nationwide',), ('State Farm',)]\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Second chain to excute the SQL queries\n",
    "execute_query = QuerySQLDataBaseTool(db=db)\n",
    "\n",
    "chain = write_query | execute_query\n",
    "chain.invoke({\"question\": \"Different companies in our table\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Fine tuning the model with basic prompt engineering for our use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt to generate SQL queries\n",
    "SQl_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are a SQLite expert. Given an input question, create a syntactically correct SQLite query to run, to answer the input question.\n",
    "Remember, your query should aim to answer the question with a single SQL statement and limit the results appropriately. You can order the results to return the most informative data in the database.\n",
    "You MUST double check your query before executing it. If you get an error while executing a query, rewrite the query and try again.\n",
    "Never query for all columns from a table. Only query the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\n",
    "Be careful not to query for columns that do not exist. Also, pay attention to which column is in which table.\n",
    "Pay attention to use the date('now') function to get the current date if the question involves \"today\".\n",
    "\n",
    "Only use the following tables:\n",
    "\n",
    "{table_info}.\n",
    "\n",
    "Question: {input}\n",
    "Provide up to {top_k} SQL variations.\"\"\"\n",
    ")\n",
    "\n",
    "# Prompt to answer the questions\n",
    "answer_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\n",
    "    \n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Result: {result}\n",
    "Answer: \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Chain 1: Generate SQL Query\n",
    "generate_sql_chain = create_sql_query_chain(prompt=SQl_prompt, llm=llm, db=db)\n",
    "\n",
    "# Initialize Chain 2: Execute SQL Query and generate structured answer\n",
    "execute_sql_chain = answer_prompt | llm | StrOutputParser()\n",
    "\n",
    "\n",
    "def execute_combined_chain(question):\n",
    "    # Step 1: Generate SQL Query\n",
    "    sql_query = generate_sql_chain.invoke({\"question\": question, \"top_k\": 1})\n",
    "    \n",
    "    # Step 2: Execute the SQL Query to get the result\n",
    "    sql_result = execute_query(sql_query)  # Ensure this returns the result of executing the SQL query\n",
    "    \n",
    "    # Step 3: Pass the necessary inputs to the final chain and format the output to include both SQL query and result\n",
    "    final_response = execute_sql_chain.invoke({\"question\": question, \"query\": sql_query, \"result\": sql_result})\n",
    "    \n",
    "    # Format the final answer to include both the SQL query and its result\n",
    "    final_answer = f\"SQL Query: {sql_query}\\n Answer: {final_response}\"\n",
    "    return final_answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Query: SELECT \"Daily_Volume\" \n",
      "FROM models \n",
      "WHERE \"Model_Name\" = 'Model 1';\n",
      " Answer: The volume of Model 1 is not clear from the SQL result provided. The query returned a list of daily volumes for Model 1, but it seems to be a list of multiple values rather than a single volume. To determine the volume of Model 1, we would need to calculate the average or total volume from the list of daily volumes provided in the SQL result.\n"
     ]
    }
   ],
   "source": [
    "# Example invocation\n",
    "question = \"what is the volume of model 1?\"\n",
    "final_answer = execute_combined_chain(question)\n",
    "print(final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Fine tunning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite\n",
      "['models']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = SQLDatabase.from_uri(\"sqlite:///dataset.db\")\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())\n",
    "\n",
    "# Define the SQL query for the view\n",
    "view_query = \"\"\"\n",
    "CREATE VIEW model_metrics_view AS\n",
    "SELECT\n",
    "    MODEL_ID,\n",
    "    CASE \n",
    "        WHEN \"Model_Type\" IN ('Multi-Class', 'Classification') \n",
    "            THEN json_extract(\"Performance_Metrics\", '$[0]')\n",
    "    END AS recall,\n",
    "    CASE \n",
    "        WHEN \"Model_Type\" IN ('Multi-Class', 'Classification') \n",
    "            THEN json_extract(\"Performance_Metrics\", '$[1]')\n",
    "    END AS precision,\n",
    "    CASE \n",
    "        WHEN \"Model_Type\" IN ('Multi-Class', 'Classification') \n",
    "            THEN json_extract(\"Performance_Metrics\", '$[2]')\n",
    "    END AS accuracy,\n",
    "    CASE\n",
    "        WHEN \"Model_type\" IN (\"Regression\")\n",
    "             THEN Performance_Metrics\n",
    "    END AS MAE\n",
    "FROM\n",
    "    models;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query to create the view\n",
    "db.run(view_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated SQL Prompt\n",
    "SQl_prompt_updated = PromptTemplate.from_template(\n",
    "    \"\"\"You are a SQLite expert. Given an input question, create a syntactically correct SQLite query to run, to answer the input question.\n",
    "Remember, your query should aim to answer the question with a single SQL statement and limit the results appropriately. You can order the results to return the most informative data in the database.\n",
    "You MUST double check your query before executing it. If you get an error while executing a query, rewrite the query and try again.\n",
    "Never query for all columns from a table. Only query the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\n",
    "Be careful not to query for columns that do not exist. Also, pay attention to which column is in which table.\n",
    "Pay attention to use the date('now') function to get the current date if the question involves \"today\".\n",
    "Only use the following tables:\n",
    "\n",
    "{table_info}.\n",
    "\n",
    "Question: {input}\n",
    "Provide up to {top_k} SQL variations.\n",
    "\n",
    "For questions related to performance metrics or accuracy, MAE or recall, you can consider joining the 'models' table with the 'model_metrics_view' view on the MODEL_ID column.\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Error: (sqlite3.OperationalError) near \"1.\": syntax error\\n[SQL: 1. \\n```sql\\nSELECT \"Model_Name\", MAX(CAST(JSON_EXTRACT(\"Performance_Metrics\", \\'$[2]\\') AS REAL)) AS \"Best_Accuracy\"\\nFROM models\\nGROUP BY \"Model_Name\"\\nORDER BY \"Best_Accuracy\" DESC\\nLIMIT 1;\\n```\\n\\n2. \\n```sql\\nSELECT \"Model_Name\", MAX(CAST(JSON_EXTRACT(\"Performance_Metrics\", \\'$[2]\\') AS REAL)) AS \"Best_Accuracy\"\\nFROM models\\nORDER BY \"Best_Accuracy\" DESC\\nLIMIT 1;\\n```\\n\\n3. \\n```sql\\nSELECT \"Model_Name\", MAX(CAST(JSON_EXTRACT(\"Performance_Metrics\", \\'$[2]\\') AS REAL)) AS \"Best_Accuracy\"\\nFROM models\\nGROUP BY \"Model_Name\"\\nORDER BY \"Best_Accuracy\" DESC\\nLIMIT 1;\\n```\\n\\n4. \\n```sql\\nSELECT \"Model_Name\", MAX(CAST(JSON_EXTRACT(\"Performance_Metrics\", \\'$[2]\\') AS REAL)) AS \"Best_Accuracy\"\\nFROM models\\nORDER BY \"Best_Accuracy\" DESC\\nLIMIT 1;\\n```\\n\\n5. \\n```sql\\nSELECT \"Model_Name\", MAX(CAST(JSON_EXTRACT(\"Performance_Metrics\", \\'$[2]\\') AS REAL)) AS \"Best_Accuracy\"\\nFROM models\\nGROUP BY \"Model_Name\"\\nORDER BY \"Best_Accuracy\" DESC\\nLIMIT 1;\\n```]\\n(Background on this error at: https://sqlalche.me/e/20/e3q8)'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_query = create_sql_query_chain(prompt=SQl_prompt_updated, llm=llm, db=db)\n",
    "execute_query = QuerySQLDataBaseTool(db=db)\n",
    "\n",
    "chain = write_query | execute_query\n",
    "chain.invoke({\"question\": \"Which model has the best accuracy\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
